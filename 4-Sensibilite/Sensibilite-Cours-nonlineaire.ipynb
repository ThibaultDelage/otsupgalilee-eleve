{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse de sensibilité non linéaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Références\n",
    "\n",
    "- O. Le Maître and O. Knio, Stochastic Spectral Methods for Uncertainty Quantication with Applications to Computational Fluid Dynamics, Series on Scientific Computation, Springer, 520 pages, (2010)\n",
    "- Andrea Saltelli, Stefano Tarantola, Francesca Compolongo, and Marco Ratto. Sensitiv-\n",
    "ity analysis in practice. John Wiley and Sons, 2004.\n",
    "- Jean-Marc Martinez. Gdr Ondes & Mascot Num , Analyse de sensibilité globale par\n",
    "décomposition de la variance. janvier 2011.\n",
    "- M. Baudin, K. Boumhaout, T. Delage, B. Iooss and J-M. Martinez. Numerical stability of Sobol' indices estimation formula, Proceedings of the SAMO 2016 Conference, Reunion Island, France, December 2016\n",
    "\n",
    "Le texte présenté ci-dessous est en partie un résumé de :\n",
    "- Introduction to sensitivity analysis with NISP, Michael Baudin (EDF), Jean-Marc Martinez (CEA), Version 0.5, February 2014\n",
    "\n",
    "qui contient les démonstrations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition intuitive\n",
    "\n",
    "Dans cette section, nous définissons les indices de Sobol' du premier ordre et totaux. \n",
    "\n",
    "Soit $X\\in\\mathbb{R}^p$ où $p$ est la dimension du vecteur d'entrée. Soit $g$ est une fonction de $\\mathbb{R}^p$ vers $\\mathbb{R}$ définie par :\n",
    "$$\n",
    "Y = g(X)\n",
    "$$\n",
    "où $Y\\in\\mathbb{R}$, pour tout $X\\in\\mathbb{R}^p$. \n",
    "\n",
    "On suppose que $X$ est une variable aléatoire de loi connue. On suppose de plus, et c'est une hypothèse très limitative, que les lois marginales de $X$ sont indépendantes.\n",
    "\n",
    "Dans la suite du texte, la présentation est grandement simplifiée si l'on suppose que les lois marginales du vecteur aléatoire $X$ sont uniformes entre 0 et 1. En d'autres termes, on fait l'hypothèse que $X$ est dans le cube unité $[0,1]^p$ :\n",
    "$$\n",
    "Y = g(X), \\qquad X\\in[0,1]^p.\n",
    "$$\n",
    "Cette dernière simplification n'est pas une limitation dans l'analyse, car il est possible de démontrer des résultats presque identiques sans cette restriction.\n",
    "\n",
    "On note $E(Y)$ l'espérance de $Y$ et $V(Y)$ la variance de $Y$. L'objectif de l'analyse de sensibilité globale est de quantifier l'impact de la variabilité de chaque variable d'entrée $X_i$ sur la variabilité de $Y$. En d'autres termes, on cherche à quantifier l'impact de $X_i$ sur $V(Y)$. \n",
    "\n",
    "Pour $i\\in\\{1,...,d\\}$, supposons que $X_i$ est une variable qui a un *fort impact* sur $Y$. Essayons de donner un sens probabiliste qui permette de quantifier cet impact. Cela implique que, si on fixe $X_i$ à une valeur $x_i\\in\\mathbb{R}$ donnée, alors la variable $Y|X_i=x_i$ a une variabilité moins grande. En d'autres termes \n",
    "$$\n",
    "V(Y|X_i=x_i) \\ll V(Y).\n",
    "$$\n",
    "Par conséquent, la différence \n",
    "$$\n",
    "\\delta_i = V(Y) - V(Y|X_i=x_i)\n",
    "$$\n",
    "est grande. \n",
    "La difficulté est que la différence $\\delta_i$ dépend de la valeur de $x_i$ que nous choisissons. La valeur la plus appropriée est sans doute $x_i=E(X_i)$, mais, puisque $X_i$ est une variable aléatoire, il y a d'autres valeurs possibles. C'est pourquoi on souhaite obtenir la différence moyenne $E(\\delta_i)$ :\n",
    "\n",
    "\\begin{align}\n",
    "E(\\delta_i) &= E\\left[V(Y) - V(Y|X_i)\\right] \\\\\n",
    "&= V(Y) - E[V(Y|X_i)].\n",
    "\\end{align}\n",
    "\n",
    "Le théorème de la variance totale implique :\n",
    "$$\n",
    "V(Y) = E[V(Y|X_i)] + V[E(Y|X_i)]\n",
    "$$\n",
    "pour $i=1,...,p$. \n",
    "On substitue $V(Y)$ dans l'équation précédente, ce qui implique :\n",
    "$$\n",
    "E(\\delta_i) = V[E(Y|X_i)]\n",
    "$$\n",
    "pour $i=1,...,p$. \n",
    "La difficulté est que l'expression précédente est absolue, et non relative à la valeur de $V(Y)$. C'est pourquoi on normalise le terme précédent par $V(Y)$. \n",
    "\n",
    "Par définition, l'indice du premier ordre de la variable $X_i$ par rapport à $g(X)$ est :\n",
    "$$\n",
    "S_i = \\frac{V[E(g(X)|X_i)]}{V(g(X))}\n",
    "$$\n",
    "pour $i=1,...,p$. \n",
    "\n",
    "L'analyse précédente montre que, si la variable $X_i$ a un impact important sur la variabilité de $Y$, alors $S_i$ est grand. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Décomposition de Sobol'\n",
    "\n",
    "If $g$ can be integrated in $[0,1]^p$, then there is a unique \n",
    "decomposition \n",
    "$$\n",
    "y = h_0 + \\sum_{i=1,2,\\ldots,p} h_i(x_i) + \\sum_{1\\leq i < j \\leq p} h_{i,j}(x_i,x_j) + \\ldots + \n",
    "h_{1,2,\\ldots,p}(x_1,x_2,\\ldots,x_p),\n",
    "$$\n",
    "where $h_0$ is a constant and the functions of the decomposition satisfy the equalities \n",
    "$$\n",
    "\\int_0^1 h_{i_1,\\ldots,i_s}(x_{i_1},\\ldots,x_{i_s})dx_{i_k} = 0,\n",
    "$$\n",
    "for any $k=1,2,\\ldots,s$ and any indices $1\\leq i_1< i_2< \\ldots< i_s\\leq p$ and \n",
    "$s=1,2,\\ldots,p$.\n",
    "\n",
    "Let us denote by the vector $u$ the set of indices $(i_1,i_2,\\ldots,i_s)$, \n",
    "where $1\\leq i_1< i_2< \\ldots< i_s\\leq p$. \n",
    "Hence, the vector $x_u=(x_{i_1},x_{i_2},\\ldots,x_{i_s})$ is made of the \n",
    "components of the vector $x=(x_1,x_2,\\ldots,x_p)$ which indices are in the set $u$. \n",
    "The equation can then be written in the \n",
    "more compact, but more abstract, equation:\n",
    "$$\n",
    "g(x) = \\sum_{u\\subseteq \\{1,2,\\ldots,p\\}} h_u(x_u).\n",
    "$$\n",
    "Moreover, we define the function $h_\\emptyset=h_0$, so that \n",
    "the equations are consistent. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Décomposition de la variance\n",
    "\n",
    "La variance de la fonction $g$ peut être décomposée en :\n",
    "$$\n",
    "V(Y)=\\sum_{i=1}^p V_i + \\sum_{1\\leq i < j\\leq p} V_{i,j} + \\ldots + V_{1,2,\\ldots,p},\n",
    "$$\n",
    "où \n",
    "\n",
    "\\begin{eqnarray}\n",
    "V_i &=& V(h_i(X_i)), \\label{eq-sde-varvi1-2} \\\\\n",
    "V_{i,j} &=& V(h_{i,j}(X_i,X_j)), \\\\\n",
    "V_{i,j,k} &=& V(h_{i,j,k}(X_i,X_j,k)), \\\\\n",
    "\\ldots&&\\\\\n",
    "V_{1,2,\\ldots,p} &=& V(h_{1,2,\\ldots,p}(X_1,X_2,\\ldots,X_p)),\n",
    "\\label{eq-sde-varv12p-2}\n",
    "\\end{eqnarray}\n",
    "or, more generally, \n",
    "\\begin{eqnarray*}\n",
    "V_u = V(h_u(X_u)),\n",
    "\\end{eqnarray*}\n",
    "for any $u \\subseteq \\{1,2,\\ldots,p\\}$.\n",
    "\n",
    "Therefore, the sensitivity indices are equal to \n",
    "\\begin{eqnarray*}\n",
    "S_i &=& \\frac{V_i}{V(Y)} , \\\\\n",
    "S_{i,j} &=& \\frac{V_{i,j}}{V(Y)} , \\\\\n",
    "S_{i,j,k} &=& \\frac{V_{i,j,k}}{V(Y)} , \\\\\n",
    "\\ldots && \\\\\n",
    "S_{1,2,\\ldots,p} &=& \\frac{V_{1,2,\\ldots,p}}{V(Y)}.\n",
    "\\end{eqnarray*}\n",
    "pour $i=1,...,p$.\n",
    "\n",
    "On peut démontrer que l'indice du premier ordre $S_i$ présenté dans l'équation précédente est égal à l'indice défini sur la base de la variance conditionnelle.\n",
    "\n",
    "For any $i=1,2,\\ldots,p$, the total sensitivity index $T_i$ \n",
    "with respect to the variable $X_i$ is the \n",
    "sum of all the sensitivity indices associated with the variable $X_i$, i.e. \n",
    "$$\n",
    "T_i = \\sum_{u\\ni i} S_u.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition de l'indice de sensibilité total\n",
    "\n",
    "Soit $X\\in\\mathbb{R}^p$. Pour tout $i=1,...,p$, soit $X_{-i}\\in\\mathbb{R}^{p-1}$ le vecteur aléatoire constitué de toutes les composantes de $X$, sauf la i-ème. En d'autres termes, on a :\n",
    "$$\n",
    "X_{-i} = (X_1,...,X_{i-1},X_{i+1},...,X_p).\n",
    "$$\n",
    "Par conséquent, le vecteur $X$ est constitué des composantes $X_i$ et $X_{-i}$, ce qui implique :\n",
    "$$\n",
    "X = (X_i,X_{-i})\n",
    "$$\n",
    "pour $i=1,...,p$.\n",
    "Ainsi la variable d'entrée de $Y=g(X)$ peut se décomposer en une part qui ne dépend que de $X_i$ et une autre part qui ne dépend que des composantes différentes de $X_i$ :\n",
    "$$\n",
    "Y = g(X_i,X_{-i}),\n",
    "$$\n",
    "pour $i=1,...,p$.\n",
    "Par définition, l'indice de sensibilité total de la variable d'entrée $X_i$ par rapport à la sortie $Y$ est :\n",
    "$$\n",
    "T_i = 1 - \\frac{V[E(g(X)|X_{-i})]}{V(g(X))}\n",
    "$$\n",
    "pour $i=1,...,p$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse des indices\n",
    "\n",
    "L'analyse des indices de sensibilité peut être faite en considérant leur valeur absolue et en les comparant entre eux. \n",
    "- On a $S_i,T_i \\in[0,1]$. \n",
    "- On a $S_i \\leq T_i$, autrement dit l'indice du premier ordre est inférieur à l'indice total. \n",
    "- L'indice du premier ordre $S_i$ représente l'impact de la variable $X_i$ seule. \n",
    "- L'indice total $T_i$ représente l'impact de la variable $X_i$, y compris ses interactions avec les autres variables. \n",
    "- Si $T_i=0$ alors la variable $X_i$ peut être remplacée par une constante. En effet, même lorsqu'elle interagit avec autres variables, elle n'a pas d'impact sur la variance de $Y$. \n",
    "- Si $S_i=T_i$ alors la variable $X_i$ n'interagit pas avec les autres variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation des indices : centrage de la fonction\n",
    "\n",
    "- Remarque 1 : on peut centrer $Y$ en le remplaçant par $Y-E(Y)$.\n",
    "- Remarque 2 : estimer les indices peut être réalisé par une intégration en dimension 2p-1, au lieu de deux intégrales  imbriquées en dimensions p-1 et 1.\n",
    "\n",
    "Soit $c\\in\\mathbb{R}$ une constante. Ajouter la constante $c$ à la fonction $g$ ne change pas ses indices de sensibilité. \n",
    "En effet, soit $\\tilde{g}$ la fonction définie par :\n",
    "$$\n",
    "\\tilde{g}(X) = g(X) + c\n",
    "$$\n",
    "pour tout $X\\in[0,1]^p$. \n",
    "\n",
    "Alors l'espérance de $\\tilde{g}$ est égale à :\n",
    "\\begin{align}\n",
    "E[\\tilde{g}(X)] = E[g(X) + c] = E[g(X)] + c.\n",
    "\\end{align}\n",
    "Sa variance est :\n",
    "\\begin{align}\n",
    "V[\\tilde{g}(X)] \n",
    "&= E[(\\tilde{g}(X)-E(\\tilde{g}(X)))^2] \\\\\n",
    "&= E[(g(X) + c-E[g(X)] - c)^2] \\\\\n",
    "&= E[(g(X) -E[g(X)])^2] \\\\\n",
    "& = V[g(X)] \n",
    "\\end{align}\n",
    "En d'autres termes, cela *décale* l'espérance, mais la variance est inchangée. \n",
    "De la même manière, la variance conditionnelle est inchangée, puisque :\n",
    "$$\n",
    "V[E(\\tilde{g}(X)|X_i)] = V[E(g(X)|X_i)]\n",
    "$$\n",
    "pour $i=1,...,p$.\n",
    "C'est pourquoi les indices de sensibilité du premier ordre et totaux sont inchangés lorsqu'on considère $\\tilde{g}$ en lieu et place de $g$:\n",
    "$$\n",
    "S_i = \\frac{V[E(\\tilde{g}(X)|X_i)]}{V(\\tilde{g}(X))}, \\qquad \n",
    "T_i = 1 - \\frac{V[E(\\tilde{g}(X)|X_{-i})]}{V(\\tilde{g}(X))}.\n",
    "$$\n",
    "\n",
    "Pour estimer les indices de sensibilité, on choisit de centrer la fonction par son espérance, c'est à dire que l'on choisit la constante $c=-E[g(X)]$. \n",
    "En d'autres termes, on considère la fonction :\n",
    "$$\n",
    "\\tilde{g}(X) = g(X) - E[g(X)]\n",
    "$$\n",
    "pour tout $X\\in[0,1]^p$. \n",
    "Par conséquent, \n",
    "$$\n",
    "E[\\tilde{g}(X)]=E[g(X) - E(g(X))]\n",
    "$$\n",
    "ce qui mène à l'équation :\n",
    "$$\n",
    "E[\\tilde{g}(X)]=0.\n",
    "$$\n",
    "\n",
    "En pratique, dans OpenTURNS, on estime donc d'abord la moyenne $E[g(X)]$ à l'aide d'une première technique d'estimation comme, par exemple, un plan Monte-Carlo simple. \n",
    "\n",
    "Il s'avère que ce centrage permet de stabiliser l'estimation des indices de Sobol' pour des raisons à la fois numériques (l'estimation de la variance est plus précise, car elle mobilise des termes dont l'amplitude est réduite) et statistiques (l'estimation de la variance n'est plus biaisée)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indices de sensibilité par une intégrale en dimension étendue\n",
    "\n",
    "Pour $i=1,...,p$, on souhaite estimer l'indice de sensibilité du premier ordre $S_i$ et l'indice total $T_i$. \n",
    "\n",
    "Supposons que l'on utiliser une méthode d'échantillonage pour estimer les intégrales requises. Il peut sembler que deux intégrations imbriquées sont nécessaires :\n",
    "- une première pour estimer l'espérance conditionnelle,\n",
    "- une seconde pour estimer la variance.\n",
    "\n",
    "Si chaque boucle nécessite $n$ calculs, alors le coût de calcul total est $n^2$, ce qui est *formidable*. \n",
    "\n",
    "En fait, une astuce proposée par Sobol' permet de remplacer cette double intégration par une seule intégration en dimension $2p-1$. En effet, \n",
    "$$\n",
    "V [E(Y|X_i)] \n",
    "= E[ E(Y|X_i)^2 ] - E(Y)^2. \n",
    "$$\n",
    "\n",
    "En pratique, OpenTURNS utilise la fonction $\\tilde{g}$ à la place de $g$, de telle sorte que $E[\\tilde{g}(X)]=0$. Non seulement cela simplifie l'expression précédente sur le plan formel, mais, surtout, cela évite de former une différence de deux carrés, pouvant mener à une perte de précision \"catastrophique\" par *cancellation*.\n",
    "\n",
    "By definition of the conditional expectation, \n",
    "$$\n",
    "E(Y|X_i=x_i) = \\int g(x_i,x_{-i}) dx_{-i}.\n",
    "$$\n",
    "\n",
    "On peut démontrer que : \n",
    "$$\n",
    "E[E(Y|X_i)^2]\n",
    "= \\int_{[0,1]^{2p-1}} g(x_i,x_{-i}) g(x_i,z_{-i}) dx_{-i} dz_{-i} dx_i.  \n",
    "$$\n",
    "Dans l'équation précédente la variable est de dimension réduite : $z_{-i}\\in\\mathbb{R}^{p-1}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimateur des indices de sensibilité\n",
    "\n",
    "Yapuka !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
