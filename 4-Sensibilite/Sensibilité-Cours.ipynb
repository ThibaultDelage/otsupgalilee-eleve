{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse de sensibilité\n",
    "\n",
    "## Analyse du modèle linéaire\n",
    "\n",
    "Assume that the random variables $X_i$ are independent, with \n",
    "mean $E(X_i)$ and finite variances $V(X_i)$, for $i=1,2,\\ldots,p$.\n",
    "Let us suppose that $Y$ is an affine function of the\n",
    "variables $X_i$:\n",
    "\\begin{eqnarray}\n",
    "Y = g(X) = \\beta_0 + \\sum_{i=1,2,\\ldots,p} \\beta_i X_i,\n",
    "\\end{eqnarray}\n",
    "where $\\beta_i$ are real parameters, for $i=1,2,\\ldots,p$.\n",
    "\n",
    "The expectation of the sum of variables is the sum of the expectations, \n",
    "so that \n",
    "\\begin{eqnarray*}\n",
    "E(Y) \n",
    "&=& E(\\beta_0) + \\sum_{i=1,2,\\ldots,p} E(\\beta_i X_i) \\\\\n",
    "&=& \\beta_0 + \\sum_{i=1,2,\\ldots,p} \\beta_i E(X_i).\n",
    "\\end{eqnarray*}\n",
    "Notice that the previous computation can be performed \n",
    "even when the variables are dependent. \n",
    "As we are going to see, we can derive a similar equality for the \n",
    "variance, although the independence of the variable is \n",
    "then a strict requirement. \n",
    "\n",
    "The standardized regression coefficient is \n",
    "\\begin{eqnarray}\n",
    "\\label{eq-SRC}\n",
    "SRC_i = \\frac{\\beta_i^2 V(X_i)}{V(Y)},\n",
    "\\end{eqnarray}\n",
    "for $i=1,2,\\ldots,p$.\n",
    "\n",
    "Obviously, we have $SRC_i\\geq 0$, for $i=1,...,p$. \n",
    "Moreover, the following proposition shows that the sum of \n",
    "standardized regression coefficients is equal to one.\n",
    "\n",
    "For an affine model $g$, the sum of the standardized regression coefficients is one:\n",
    "\\begin{eqnarray}\n",
    "\\label{eq-SRCsum}\n",
    "SRC_1 + SRC_2 + \\ldots + SRC_p = 1. \\qquad \\textrm{(1)}\n",
    "\\end{eqnarray}\n",
    "\n",
    "*Proof*\n",
    "\n",
    "Since the variables $X_i$ are independent, the variance of the \n",
    "sum of variables is the sum of the variances. \n",
    "Hence, \n",
    "\\begin{eqnarray*}\n",
    "V(Y) \n",
    "&=& V(\\beta_0) + \\sum_{i=1,2,\\ldots,p} V(\\beta_i X_i).\n",
    "\\end{eqnarray*}\n",
    "But $V(\\beta_0)=0$ and, for each $i=1,2,\\ldots,p$, \n",
    "we have $V(\\beta_i X_i)=\\beta_i^2 V(X_i)$. \n",
    "This leads to the equality\n",
    "\\begin{eqnarray*}\n",
    "V(Y) \n",
    "&=& \\sum_{i=1,2,\\ldots,p} \\beta_i^2 V(X_i).\n",
    "\\end{eqnarray*}\n",
    "Hence, each term $\\beta_i^2 V(X_i)$ is the part of the \n",
    "total variance $V(Y)$ which is caused by the variable $X_i$.\n",
    "We divide the previous equality by $V(Y)$ and get the \n",
    "equation (1), which concludes the proof. $\\blacksquare$\n",
    "\n",
    "## Linear correlation coefficient and SRC indices\n",
    "\n",
    "In this section, we present the link between the linear \n",
    "correlation coefficients of an affine model, and the \n",
    "standardized regression coefficients.\n",
    "\n",
    "Assume that the random variables $X_i$ are independent, with \n",
    "mean $E(X_i)$ and finite variances $V(X_i)$, for $i=1,2,\\ldots,p$.\n",
    "Let us consider the random variable $Y$, which depends linearily on the \n",
    "variables $X_i$. \n",
    "We are interested in the correlation coefficient $Corr(Y,X_i)$.\n",
    "\n",
    "Let us consider two jointly distributed random variables $X$ and $Y$. \n",
    "The covariance is \n",
    "\\begin{eqnarray}\n",
    "Cov(Y,X_i) = E[(Y-E(Y))(X_i-E(X_i))],\n",
    "\\end{eqnarray}\n",
    "for $i=1,2,\\ldots,p$.\n",
    "The linear correlation coefficient is \n",
    "\\begin{eqnarray}\n",
    "\\label{eq-corrcoef}\n",
    "Corr(Y,X_i) = \\frac{Cov(Y,X_i)}{\\sqrt{V(Y)}\\sqrt{V(X_i)}}\n",
    "\\end{eqnarray}\n",
    "for $i=1,2,\\ldots,p$.\n",
    "\n",
    "Assume that the output $Y$ is the affine model.\n",
    "Assume that the input variables $X_i$ are independent. \n",
    "Therefore \n",
    "\\begin{eqnarray}\n",
    "\\label{prop-sicorr2}\n",
    "SRC_i = Corr(Y,X_i)^2,\n",
    "\\end{eqnarray}\n",
    "for $i=1,2,\\ldots,p$.\n",
    "\n",
    "*Proof*\n",
    "\n",
    "We have \n",
    "\\begin{eqnarray*}\n",
    "Cov(Y,X_i) \n",
    "&=& Cov(\\beta_0,X_i) + \\beta_1 Cov(X_1,X_i)+ \\beta_2 Cov(X_2,X_i) + \\ldots  \\\\\n",
    "&& + \\beta_i Cov(X_i,X_i) + \\ldots + \\beta_p Cov(X_p,X_i),\n",
    "\\end{eqnarray*}\n",
    "because the covariance function is linear with respect to \n",
    "its arguments. \n",
    "Obviously, we have $Cov(\\beta_0,X_i)=0$ since $\\beta_0$ is a constant. \n",
    "Moreover, the random variables $X_i$ are independent, which implies that $Cov(X_j,X_i) = 0$, \n",
    "for any $j \\neq i$. \n",
    "Therefore, \n",
    "\\begin{eqnarray*}\n",
    "Cov(Y,X_i) \n",
    "&=& \\beta_i Cov(X_i,X_i) \\\\\n",
    "&=& \\beta_i V(X_i).\n",
    "\\end{eqnarray*}\n",
    "Hence, the correlation coefficient can be simplified into\n",
    "\\begin{eqnarray*}\n",
    "Corr(Y,X_i) \n",
    "&=& \\frac{\\beta_i V(X_i)}{\\sqrt{V(Y)} \\sqrt{V(X_i)}} \\\\\n",
    "&=& \\frac{\\beta_i \\sqrt{V(X_i)}}{\\sqrt{V(Y)}}.\n",
    "\\end{eqnarray*}\n",
    "We square the previous equality and get\n",
    "\\begin{eqnarray*}\n",
    "Corr(Y,X_i)^2\n",
    "&=& \\frac{\\beta_i^2 V(X_i)}{V(Y)}.\n",
    "\\end{eqnarray*}\n",
    "In the previous equality, we recognize the SRC coefficient, \n",
    "which concludes the proof. $\\blacksquare$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
